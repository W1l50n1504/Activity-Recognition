import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa

from abc import ABCMeta, abstractmethod, ABC
# from dbn_libraries.tensorflow import SupervisedDBNClassification
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from tensorflow.python.keras.layers import Bidirectional, LSTM, MaxPooling1D
from tensorflow.keras import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Conv2D, Conv1D, MaxPool1D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam

from com.utility import *

gpu_devices = tf.config.experimental.list_physical_devices('GPU')
for device in gpu_devices:
    tf.config.experimental.set_memory_growth(device, True)

METRICS = [
    tf.keras.metrics.Accuracy(name="Accuracy"),
    tf.keras.metrics.Precision(name="precision"),
    tf.keras.metrics.Recall(name="recall"),
    tfa.metrics.F1Score(num_classes=6, threshold=0.5),
    tf.keras.metrics.AUC(name="auc")
]

RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)


class BaseModel(metaclass=ABCMeta):

    def __init__(self):
        self.X = None
        self.y = None
        self.model = None
        self.checkpoint = None
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None
        self.X_val = None
        self.y_val = None
        self.history = None
        self.epochs = 100
        self.dsConfig = 0

        self.loadData()
        self.dataProcessing()

    def loadData(self):
        """
        carica i dati dai dataset

        :return:
        """

        x1, y1 = loadUCIHAR()
        x2, y2 = loadData(kuharPath)  # c'è qualcosa che non va nel caricamento delle label di kuhar controlla meglio
        x3, y3 = loadData(motionPath)

        if self.dsConfig == 0:
            # train uci + ku test motion
            x3 = np.array(x3)
            y3 = np.array(y3)

            self.X = pd.concat([x1, x2])

            y1 = np.array(y1)
            y2 = np.array(y2)
            self.y = np.concatenate((y1, y2), axis=0)

            self.X_test = x3
            self.y_test = y3

        elif self.dsConfig == 1:
            # train ku + motion test uci
            # x1 = np.array(x1)
            # y1 = np.array(y1)

            self.X = pd.concat([x3, x2])
            self.y = pd.concat([y3, y2])
            self.X_test = x1
            self.y_test = y1

        elif self.dsConfig == 2:
            # train uci + motion test ku
            y2 = np.array(y2)
            x2 = np.array(x2)

            self.X = pd.concat([x1, x3])
            self.y = pd.concat([y1, y3])
            self.X_test = x2
            self.y_test = y2

        elif self.dsConfig == 3:
            self.X, self.y = loadData()

        elif self.dsConfig == 4:
            self.X, self.y = loadKUHAR()

    def dataProcessing(self):
        """
        funzione in cui si effettuano tutte le elaborazinoi sui dati
        """

        self.X = np.array(self.X)

        if self.dsConfig == 3 or self.dsConfig == 4:
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.3,
                                                                                    random_state=42)
            self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X_train, self.y_train,
                                                                                  test_size=0.1, random_state=42)
        else:
            self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X, self.y,
                                                                                  test_size=0.1, random_state=42)

        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)
        enc = enc.fit(self.y_train)

        self.y_train = enc.transform(self.y_train)
        self.y_test = enc.transform(self.y_test)
        self.y_val = enc.transform(self.y_val)
        """
        self.y_train = np.array(self.y_train).reshape(-1, 1)
        self.y_test = np.array(self.y_test).reshape(-1, 1)
        self.y_val = np.array(self.y_val).reshape(-1, 1)
        """
        print('dimensione reshape', self.X_train[..., np.newaxis].shape)
        print('dimensione reshape', self.X_test[..., np.newaxis].shape)
        print('dimensione reshape', self.X_val[..., np.newaxis].shape)

        if self.dsConfig == 0:
            # valori da utilizzare se si utilizza UCIHAR e KUHAR
            self.X_train = self.X_train.reshape(11991, 12, 1)
            self.X_test = self.X_test.reshape(5414, 12, 1)
            self.X_val = self.X_val.reshape(1333, 12, 1)

        elif self.dsConfig == 1:
            # MotionSense KUHAR
            self.X_train = self.X_train.reshape(20590, 12, 1)
            self.X_test = self.X_test.reshape(10299, 12, 1)
            self.X_val = self.X_val.reshape(2288, 12, 1)

        elif self.dsConfig == 2:
            # UCIHAR KUHAR
            self.X_train = self.X_train.reshape(20781, 12, 1)
            self.X_test = self.X_test.reshape(10087, 12, 1)
            self.X_val = self.X_val.reshape(2309, 12, 1)

        elif self.dsConfig == 3:
            # valori da utilizzare se tutti e tre i dataset sono uniti
            self.X_train = self.X_train.reshape(20900, 12, 1)
            self.X_test = self.X_test.reshape(9954, 12, 1)
            self.X_val = self.X_val.reshape(2323, 12, 1)

        elif self.dsConfig == 4:

            # UCIHAR y_train.shape = 6
            self.X_train = self.X_train.reshape(6488, 12, 1)
            self.X_test = self.X_test.reshape(3090, 12, 1)
            self.X_val = self.X_val.reshape(721, 12, 1)
            """
     
            
            # MotionSense y_train.shape = 5
            self.X_train = self.X_train.reshape(7423, 12, 1)
            self.X_test = self.X_test.reshape(3536, 12, 1)
            self.X_val = self.X_val.reshape(825, 12, 1)
                        # KUHAR y_train.shape = 5
            self.X_train = self.X_train.reshape(5207, 12, 1)
            self.X_test = self.X_test.reshape(2480, 12, 1)
            self.X_val = self.X_val.reshape(579, 12, 1)
            """

        self.y = np.array(self.y)
        print(self.y)

    @abstractmethod
    def modelCreation(self):
        """:cvar"""
        pass

    @abstractmethod
    def fit(self):
        """
        verrà implementato dai modelli
        """
        pass

    def plot(self):

        rounded_labels = np.argmax(self.y_test, axis=1)
        y_pred = self.model.predict_classes(self.X_test)

        mat = confusion_matrix(rounded_labels, y_pred)
        plot_confusion_matrix(conf_mat=mat, show_normed=True, figsize=(10, 10))

        plt.figure(figsize=(10, 10))
        array = confusion_matrix(rounded_labels, y_pred)

        mat = confusion_matrix(rounded_labels, y_pred)
        plot_confusion_matrix(conf_mat=mat, show_normed=True, figsize=(10, 10))

        plt.figure(figsize=(10, 10))
        array = confusion_matrix(rounded_labels, y_pred)

        if self.dsConfig == 4:

            df_cm = pd.DataFrame(array, range(6), range(6))
            df_cm.columns = ["Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying"]
            df_cm.index = ["Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying"]

            sns.set(font_scale=1)  # for label size
            sns.heatmap(df_cm, annot=True, annot_kws={"size": 12},
                        yticklabels=("Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying"),
                        xticklabels=("Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying"))

        else:
            df_cm = pd.DataFrame(array, range(7), range(7))
            df_cm.columns = ["Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying", "Jogging"]
            df_cm.index = ["Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying", "Jogging"]

            sns.set(font_scale=1)  # for label size
            sns.heatmap(df_cm, annot=True, annot_kws={"size": 12},
                        yticklabels=(
                            "Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying", "Jogging"),
                        xticklabels=(
                            "Walking", "W_Upstairs", "W_Downstairs", "Sitting", "Standing", "Laying", "Jogging"))

        plt.show()

        # Plot training & validation accuracy values
        plt.figure(figsize=(15, 8))
        epoch_range = range(1, self.epochs + 1)
        plt.plot(epoch_range, self.history.history['Accuracy'])
        plt.plot(epoch_range, self.history.history['val_Accuracy'])
        plt.title('Model accuracy')
        plt.ylabel('Validation Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Val'], loc='upper left')
        # plt.savefig(trainingValAccBLSTM)
        plt.show()

        # Plot training & validation auc values
        plt.figure(figsize=(15, 8))
        epoch_range = range(1, self.epochs + 1)
        plt.plot(epoch_range, self.history.history['auc'])
        plt.plot(epoch_range, self.history.history['val_auc'])
        plt.title('Model auc')
        plt.ylabel('auc')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Val'], loc='upper left')
        # plt.savefig(TrainingValAucBLSTM)
        plt.show()

        # Plot training & validation loss values
        plt.figure(figsize=(15, 8))
        plt.plot(epoch_range, self.history.history['loss'])
        plt.plot(epoch_range, self.history.history['val_loss'])
        plt.title('Model loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Val'], loc='upper left')
        # plt.savefig(ModelLossBLSTM)
        plt.show()

    def main(self):
        self.modelCreation()
        self.fit()
        self.plot()
